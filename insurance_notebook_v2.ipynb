{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7dd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590e75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import data\n",
    "from IPython.display import HTML, Markdown\n",
    "# import myWidgets\n",
    "import logisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import Model\n",
    "import Trackers.ModelTracker as ModelTracker\n",
    "import plot_tools\n",
    "import writing_tools\n",
    "import FeatureTools\n",
    "import Trackers.FeatureTracker as FeatureTracker\n",
    "import Trackers.DataTracker as DataTracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ff4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.get_data()\n",
    "model_tracker = ModelTracker.ModelTracker()\n",
    "feature_tracker = FeatureTracker.FeatureTracker(df.copy())\n",
    "data_tracker = DataTracker.X_tracker()\n",
    "cols_to_scale = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003995d",
   "metadata": {},
   "source": [
    "$$\\text{logit } p = \\ln \\frac{p}{1-p} = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n = z$$\n",
    "$$ e^z = \\frac{p}{1-p} \\iff p = \\frac{e^z}{1 + e^z} $$\n",
    "$$p = P(\\text{CARAVAN} = 1 | X = x)$$\n",
    "\n",
    "$$\\text{odds } = \\frac{p}{1-p}$$\n",
    "\n",
    "$$OR = e^{\\beta}$$\n",
    "\n",
    "Le odds-ratio permet de mesurer l'effet d'une variable sur la probabilité qu'un évenements se produise (CARAVAN = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb2e26",
   "metadata": {},
   "source": [
    "Il faut que je calcul l'intervalle de confiance pour assumer qu'une variable est significative selon la valeur de son $OR$.\n",
    "\n",
    "Pour calculer un intervalle de confiance, j'ai besoin de l'écart-type des variables. Mais puisque OR dépend des rélations entres les variables, je dois utiliser une matrice de covariance, qui est l'inverse de la matrice de Fisher Information.\n",
    "\n",
    "**Fisher Information :** \n",
    "\n",
    "$$\\theta = \\mathbb{E} \\left[ \\left( \\frac{\\partial}{\\partial \\theta} \\log f(X; \\theta) \\right)^2 \\right]$$\n",
    "\n",
    "$\\mathbb{E} = $  espérance de $X$ \\\n",
    "$f(X; \\theta) = $ fonction de densité de $X$\n",
    "\n",
    "Forme matrice : \n",
    "\n",
    "$$p_i = P(\\text{CARAVAN} = 1 | X_i) = \\sigma(X_i \\cdot \\beta) = \\dfrac{e^{X_i \\cdot \\beta}}{1 + e^{X_i \\cdot \\beta}} \\\\\n",
    "\\ell(\\beta) = \\sum^n_{i=1} \\log f(X_i; \\theta) =  \\sum_{i=1}^{n} \\Big[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\Big] = - \\text{cost function } \\\\ \n",
    "(y_i = \\text{la valeur observée du target (0 ou 1))} \n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial \\beta} = X^T (y - p) = \\text{gradient ascent} \\\\\n",
    "\\frac{\\partial^2 \\ell}{\\partial \\beta\\, \\partial \\beta^T} = -X^T W X = \\text{variation du gradient ascent}\n",
    "$$\n",
    "\n",
    "$$\\text y_i \\sim Bernoulli(p) \\iff Var(y_i) = p_i(1 - p_i)$$\n",
    "\n",
    "$$ W = diag(p_i(1 - p_i)) = Var(Y) =\n",
    "\\begin{bmatrix}\n",
    "p_1(1-p_1) & 0 & \\cdots & 0 \\\\\n",
    "0 & p_2(1-p_2) & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & p_n(1-p_n)\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Sa calcul la précision de l'estimation d'un coefficient \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d15ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC         : 0.7951\n",
      "Precision   : 0.1697\n",
      "Recall      : 0.5286\n",
      "F1          : 0.2569\n",
      "Threshold   : 0.1000\n",
      "[[914 181]\n",
      " [ 33  37]]\n"
     ]
    }
   ],
   "source": [
    "categorical_non_ordinales = ['MOSTYPE', 'MOSHOOFD']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_non_ordinales, prefix=categorical_non_ordinales, dtype=int, drop_first=True)\n",
    "X_base_one_hot = df_encoded.copy()\n",
    "featureTester = FeatureTracker.FeatureTracker(X_base_one_hot)\n",
    "X_train_np, y_train_np, X_val_np, y_val_np = featureTester.return_split_train_eval(toNpy=True)\n",
    "\n",
    "model = featureTester.get_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ea1723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.753692681997185e-11\n"
     ]
    }
   ],
   "source": [
    "coeff = model.w\n",
    "bias = model.b\n",
    "odds_ratio = np.exp(coeff)\n",
    "confiance = 0.95\n",
    "\n",
    "def fisher_info(X, w, b):\n",
    "    z = X @ w + b\n",
    "    p = logisticRegression.sigmoid(z)\n",
    "    W = np.diag(p * (1-p))\n",
    "    fi = X.T @ W @ X\n",
    "    return fi\n",
    "\n",
    "fi = fisher_info(X_train_np, coeff, bias)\n",
    "print(np.linalg.det(fi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf06b2",
   "metadata": {},
   "source": [
    "La matrice de covariance est proche d'être singuliaire, car $\\text{det}(\\text{fisher\\_information}) \\approx 0$, elle est presque non-inversible. \\\n",
    "Si je l'inverse, il y a des variances gigantesque et positive/négative.\n",
    "\n",
    "- Si on regarde qu'elle variance $\\lt$ 0, on trouve que 14 d'entres elles sont négatives (elles sont aussi gigantesques) $( Var(y) \\lt -10^{14})$. \\\n",
    "29 sont des variables catégoriques non-ordinales à propos du type de cients et 2 sont à propos du nombre et la contribution d'assurance surfboard. \\\n",
    "\n",
    "- Si on regarde ceux qui sont géante, on trouve qu'il y en a 32 d'entres elles qui sont gigantesques.\n",
    "\n",
    "\n",
    "C'est un signe que ces variables sont peut-être complètement séparer des données, donc pourait prédire constamment le même résultat, ce qui indique que leur $\\beta$ tend vers $\\pm \\infin$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba0d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "négatif count in variance:                14\n",
      "négatif gigantesque count in variance:    14\n",
      "Gigantesque count in variance:            32\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.linalg.inv(fi)\n",
    "#std = np.sqrt(np.diag(cov_matrix))\n",
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'var': np.diag(cov_matrix),\n",
    "})\n",
    "\n",
    "print('négatif count in variance:               ', coef_df[coef_df['var'] < 0].shape[0])\n",
    "print('négatif gigantesque count in variance:   ', coef_df[coef_df['var'] <= -10**13].shape[0])\n",
    "print('Gigantesque count in variance:           ', coef_df[coef_df['var'] >= 10**(14)].shape[0])\n",
    "\n",
    "huge_neg_coeff_cols = coef_df[coef_df['var'] < 0]['feature'].values\n",
    "huge_pos_coeff_cols = coef_df[coef_df['var'] >= 10**(14)]['feature'].values\n",
    "\n",
    "inf_coef_cols = np.concatenate((huge_neg_coeff_cols, huge_pos_coeff_cols), axis=0)\n",
    "X_train_inf_coef = X_train[inf_coef_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8c77e",
   "metadata": {},
   "source": [
    "Si on vérifie, on trouve qu'il y a quelque une variable qui prédit toujours CARAVAN = 0 et le reste sont des cas très rares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669eb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "huge_neg_coeff_cols = coef_df[coef_df['var'] < 0]['feature'].values\n",
    "huge_pos_coeff_cols = coef_df[coef_df['var'] >= 10**(14)]['feature'].values\n",
    "\n",
    "inf_coef_cols = np.concatenate((huge_neg_coeff_cols, huge_pos_coeff_cols), axis=0)\n",
    "X_train_inf_coef = X_train[inf_coef_cols].copy()\n",
    "\n",
    "cols_with_zeros_targets = []\n",
    "cols_with_all_targets = []\n",
    "cols_with_rare_outcomes = {}\n",
    "\n",
    "for c in inf_coef_cols:\n",
    "    crossTab = pd.crosstab(X_train_inf_coef[c], y_train)\n",
    "\n",
    "    if 1 in crossTab.index:\n",
    "        #print(f'\\n{c} = 1')\n",
    "        not_target_count = crossTab.loc[1, 0]\n",
    "        target_count = crossTab.loc[1, 1]\n",
    "        #print(f\"    (CARAVAN=0) : {not_target_count}\")\n",
    "\n",
    "        if target_count == 0:\n",
    "            #print(f'    Prédit toujours CARAVAN=0')\n",
    "            cols_with_zeros_targets.append(c)\n",
    "        elif not_target_count == 0:\n",
    "            #print(f'    Prédit toujours CARAVAN=1')\n",
    "            cols_with_all_targets.append(c)\n",
    "        else:\n",
    "           #print(f\"    (CARAVAN=1): {target_count}\")\n",
    "           cols_with_rare_outcomes[c] = np.array([target_count, not_target_count])\n",
    "    else:\n",
    "        print('what?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f09ba",
   "metadata": {},
   "source": [
    "Les variables qui prédisent tous le temps CARAVAN = 0 dans le training set sont inutiles donc je vais les retirer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6857ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureTester.remove_list(cols_with_zeros_targets)\n",
    "X = featureTester.flush_to_df()\n",
    "\n",
    "X_train_np, y_train_np, X_val_np, y_val_np = featureTester.return_split_train_eval(toNpy=True)\n",
    "model = Model.create_model(X_train_np, y_train_np, X_val_np, y_val_np, learning_rate=0.01, set_threshold_to=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc33e8",
   "metadata": {},
   "source": [
    "Les autres variables ne sont pas complètement séparer, mais peut-etre souffre de multicolinéarité, ce qui serait la cause de leur variance gigantesque.\n",
    "\n",
    "Précédemment, j'avais utilisé une matrice de corrélation pour trouver les corrélations entre variables, mais le problème est qu'elle évalue seulement la colinéarité entre deux variables. Pour ce problème, c'est mieux d'utiliser le VIF, car il permet d'analyser l'impact de tout les autres variables sur la variance d'un coefficient, ce qui est exactement ce que j'ai besoin pour trouver la cause de la variance énorme des variables restantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b38e0",
   "metadata": {},
   "source": [
    "$$VIF = \\dfrac{1}{1-R^2}$$\n",
    "$$\n",
    "X_i = \\beta_0 + \\sum_{j \\neq i}(\\beta_j X_j) + \\varepsilon_i \\\\\n",
    "\\hat{\\beta} = (X^TX)^{-1}X^Ty \n",
    "$$\n",
    "$$\\varepsilon_i = X_i -\\hat{X_i} \\iff Var(\\varepsilon_i) = Var(X_i) -Var(\\hat{X_i})$$\n",
    "$$\\sum{\\varepsilon_i} = \\sum{(X_i -\\hat{X_i})} = 0$$\n",
    "$$\n",
    "R^{2}_{i} = \\frac{Var(\\hat{X_i})}{Var(X_i)} = \\frac{ Var({X_i}) - Var(\\varepsilon_i)}{Var(X_i)} \n",
    "= 1 - \\frac{Var(\\varepsilon_i)}{Var({X_i})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d41ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(X, y):\n",
    "    w = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    return w\n",
    "\n",
    "def regressionLineaire(X, y):\n",
    "    w = ols(X, y)\n",
    "    residual = y - X @ w\n",
    "    return w, residual\n",
    "\n",
    "def auxRegLin(X, eps, tol=1e-12):\n",
    "    var_residual = np.sum(eps**2)\n",
    "    xm = np.mean(X)\n",
    "    var_X = np.sum((X - xm)**2)\n",
    "    if var_X <= tol: return 0\n",
    "    return (1 - var_residual/var_X)\n",
    "    \n",
    "def vif(X, cols):\n",
    "    vif_res = {}\n",
    "    for c in cols:\n",
    "        X_i = X[c].to_numpy()\n",
    "        X_hat_i = X.drop(c, axis=1).to_numpy()\n",
    "        X_hat = np.column_stack([np.ones(len(X_i)), X_hat_i])\n",
    "        w, residu = regressionLineaire(X_hat, X_i)\n",
    "        R2 = auxRegLin(X_i, residu)\n",
    "        vif = np.inf if np.isclose(1 - R2, 0) else 1 / (1 - R2)\n",
    "        vif_res[c] = vif\n",
    "    return pd.DataFrame.from_dict(vif_res, orient='index', columns=['VIF']).sort_values(by='VIF', ascending=False)\n",
    "\n",
    "df_vif = vif(X.drop('CARAVAN', axis=1), cols_with_rare_outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbff3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mid_corr = df_vif[(df_vif['VIF'] > 1) & (df_vif['VIF'] <= 5)].index\n",
    "index_high_corr = df_vif[(df_vif['VIF'] > 5) & (df_vif['VIF'] <= 10)].index\n",
    "index_serious_corr = df_vif[(df_vif['VIF'] > 10)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb906d",
   "metadata": {},
   "source": [
    "Tout les variables avec un $R^2$ = $\\inf$ (colinéarité parfaite, donc parfaitement prédite par les autres variables) sont des variables de types MOSTYPE (customer sub-type) ou MOSHOOFD (customer main type). Je vais les retirer puisqu'elle n'aide pas le modèle. Les seules que je vais garder sont eux avec 1 < VIF < 5. Plus grand leur résultat VIF indique qu'ils sont hautement corrélés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77a71a",
   "metadata": {},
   "source": [
    "Les métriques restent similaires à avant le retrait de ces variables, donc c'est une confirmation que le retrait n'a pas tellement affecté les prédictions du modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ae07f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC         : 0.7944\n",
      "Precision   : 0.1689\n",
      "Recall      : 0.5286\n",
      "F1          : 0.2561\n",
      "Threshold   : 0.1000\n",
      "[[913 182]\n",
      " [ 33  37]]\n"
     ]
    }
   ],
   "source": [
    "featureTester.remove_list(index_high_corr)\n",
    "featureTester.remove_list(index_serious_corr)\n",
    "\n",
    "X = featureTester.flush_to_df()\n",
    "\n",
    "model = featureTester.get_trained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5934fb",
   "metadata": {},
   "source": [
    "Maintenant, on retourne au calcul de Fisher information pour trouver les variables les plus utiles pour prédire CARAVAN=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2972dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.615584458150003e+94\n"
     ]
    }
   ],
   "source": [
    "X_train_np, y_train_np, X_val_np, y_val_np = featureTester.return_split_train_eval(toNpy=True)\n",
    "fi = FeatureTools.fisher_info(X_train_np, model.w, model.b)\n",
    "print(np.linalg.det(fi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af54de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de eigen values négative:  1\n"
     ]
    }
   ],
   "source": [
    "eigen_values = np.linalg.eigvals(fi)\n",
    "print('Nombre de eigen values négative: ', (eigen_values<0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c485344e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|         |           0 |\n",
       "|:--------|------------:|\n",
       "| PZEILPL | 0.707107    |\n",
       "| AZEILPL | 0.707107    |\n",
       "| AVRAAUT | 5.81657e-15 |\n",
       "| AGEZONG | 4.81223e-15 |\n",
       "| AWAOREG | 2.64977e-15 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_values, eigen_vectors = np.linalg.eig(fi)\n",
    "negative_values = (eigen_values<0)\n",
    "idx_problem = [i for i, is_negative in enumerate(negative_values) if is_negative]\n",
    "\n",
    "problematic_vector = eigen_vectors[:, idx_problem]\n",
    "\n",
    "index = X.drop('CARAVAN', axis=1).columns\n",
    "\n",
    "problematic_variables_df = pd.DataFrame(np.abs(problematic_vector), index=index)\n",
    "Markdown(problematic_variables_df.sort_values(by=0, ascending=False).head().to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1c475",
   "metadata": {},
   "source": [
    "Seulement une personne dans le training set a PZEILPL ou AZEILPL > 0 et CARAVAN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c759ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   PZEILPL (CARAVAN=1) |   AZEILPL (CARAVAN=1) |\n",
      "|---:|----------------------:|----------------------:|\n",
      "|  0 |                   277 |                   277 |\n",
      "|  1 |                     1 |                     1 |\n"
     ]
    }
   ],
   "source": [
    "print(FeatureTools.get_target_count_of_variables(X_train, y_train, ['PZEILPL', 'AZEILPL']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615a375",
   "metadata": {},
   "source": [
    "Parfait, maintenant le determinant n'est plus négatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62f77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.848675513629938e+128\n"
     ]
    }
   ],
   "source": [
    "featureTester.remove_list(['PZEILPL', 'AZEILPL'])\n",
    "X = featureTester.flush_to_df()\n",
    "model = featureTester.get_trained_model(print_stats=False)\n",
    "\n",
    "X_train_np, y_train_np, X_val_np, y_val_np = featureTester.return_split_train_eval(toNpy=True)\n",
    "fi = FeatureTools.fisher_info(X_train_np, model.w, model.b)\n",
    "print(np.linalg.det(fi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cabfbfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | feature   |   $\\beta_n$ |   $OR$ |   $bi_{OR}$ |   $bs_{OR}$ |\n",
       "|---:|:----------|------------:|-------:|------------:|------------:|\n",
       "| 44 | PPERSAUT  |      0.1974 | 1.2182 |      1.1104 |      1.3365 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "coeff = model.w \n",
    "bias = model.b \n",
    "odds_ratio = np.exp(coeff) \n",
    "confiance = 0.95\n",
    "\n",
    "X_train_np, y_train_np, X_val_np, y_val_np = featureTester.return_split_train_eval(toNpy=True)\n",
    "\n",
    "fi = FeatureTools.fisher_info(X_train_np, model.w, model.b)\n",
    "cov_matrix = np.linalg.inv(fi)\n",
    "std = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "surface = 1 - (1-confiance)/2\n",
    "z = st.norm.ppf(surface)\n",
    "\n",
    "bi = coeff - z * std\n",
    "bs = coeff + z * std\n",
    "\n",
    "bi_or = np.exp(bi)\n",
    "bs_or = np.exp(bs)\n",
    "    \n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X.drop('CARAVAN', axis=1).columns,\n",
    "    '$\\\\beta_n$': model.w,\n",
    "    '$OR$': odds_ratio,\n",
    "    '$bi_{OR}$': bi_or,\n",
    "    '$bs_{OR}$': bs_or\n",
    "})\n",
    "\n",
    "coef_df = coef_df.round(4)\n",
    "\n",
    "mask_signif = (coef_df['$bi_{OR}$'] > 1) | (coef_df['$bs_{OR}$'] < 1)\n",
    "Markdown(coef_df[mask_signif].to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727ea38",
   "metadata": {},
   "source": [
    "$$OR > 1 \\to \\text{augmente les chances que CARAVAN = 1}$$\n",
    "$$OR < 1 \\to \\text{diminue les chances que CARAVAN = 1}$$\n",
    "$$OR = 1 \\to \\text{aucun effet sur les chances que CARAVAN = 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f036694",
   "metadata": {},
   "source": [
    "Présentement, voici à quoi ressemble le modèle sans aucune variable additionnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31dd6828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset DATA_FE2_NO_ADDED_VARS_JUST_FILTERED_BASE saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_V4 = 'DATA_FE2_NO_ADDED_VARS_JUST_FILTERED_BASE'\n",
    "X = featureTester.flush_to_df()\n",
    "data_tracker.add(DATA_V4, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ceabd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAANHANG', 'ABROM', 'ABYSTAND', 'AGEZONG', 'AMOTSCO', 'AVRAAUT',\n",
       "       'AWALAND', 'AWAOREG', 'AWAPART', 'AWERKT', 'MAUT0', 'MAUT1', 'MFALLEEN',\n",
       "       'MFGEKIND', 'MFWEKIND', 'MGODPR', 'MHHUUR', 'MHKOOP', 'MINK4575',\n",
       "       'MINKM30', 'MOPLHOOG', 'MOPLLAAG', 'MOPLMIDD', 'MRELGE', 'MRELOV',\n",
       "       'MSKC', 'MZFONDS', 'MZPART', 'PAANHANG', 'PBROM', 'PBYSTAND', 'PGEZONG',\n",
       "       'PMOTSCO', 'PTRACTOR', 'PVRAAUT', 'PWALAND', 'PWAOREG', 'PWAPART'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "cols = X_train.columns\n",
    "\n",
    "df_vif = FeatureTools.vif(X_train, cols)\n",
    "cols = df_vif[df_vif['VIF'] >= 10].index\n",
    "cols.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a423fd0",
   "metadata": {},
   "source": [
    "Tout les variables qui débute par A sont des variables qui indique le nombre de police d'assurance x.\n",
    "Je vais tout les regrouper en une seule variable 'total' puisqu'elle mesure la meme chose que les variables P mais sous une différentes unité. (Nombre de polices vs Contribution). \n",
    "\n",
    "| Type d'assurance                          | Variables associées | Description complète |\n",
    "|------------------------------------------|-------------------|--------------------|\n",
    "| Assurance vie / accidents / santé         | ALEVEN, APERSONG, AGEZONG, AWAOREG, ABRAND, ABYSTAND | Number of life insurances, private accident insurance policies, family accidents insurance policies, disability insurance policies, fire policies, social security insurance policies |\n",
    "| Third party insurance                     | AWAPART, AWABEDR, AWALAND | Private third party insurance, third party insurance (firms), third party insurance (agriculture) |\n",
    "| Assurance véhicule quotidien              | APERSAUT, AMOTSCO, ABROM | Number of car policies, motorcycle/scooter policies, moped policies |\n",
    "| Assurance véhicule de travail / poids lourd | AVRAAUT, ATRACTOR, AWERKT, AAANHANG, ABESAUT | Number of lorry, tractor, agricultural machines, trailer policies, delivery van policies |\n",
    "| Assurance propriété                       | AINBOED           | Number of property insurance policies |\n",
    "| Assurance véhicule de loisir              | APLEZIER, AFIETS, AZEILPL | Number of boat, bicycle, surfboard policies |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4717c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----- Avant le regroupement -----|\n",
      "AUC         : 0.7944\n",
      "Precision   : 0.1689\n",
      "Recall      : 0.5286\n",
      "F1          : 0.2561\n",
      "Threshold   : 0.1000\n",
      "[[913 182]\n",
      " [ 33  37]]\n"
     ]
    }
   ],
   "source": [
    "print('|----- Avant le regroupement -----|')\n",
    "model = featureTester.get_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e92cde63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----- Après le regroupement -----|\n",
      "AUC         : 0.7943\n",
      "Precision   : 0.1735\n",
      "Recall      : 0.5429\n",
      "F1          : 0.2630\n",
      "Threshold   : 0.1000\n",
      "[[914 181]\n",
      " [ 32  38]]\n"
     ]
    }
   ],
   "source": [
    "featureTester.restore('AZEILPL') # car retirer précédemment\n",
    "X = featureTester.flush_to_df()\n",
    "\n",
    "life_accidents_health = np.array(['ALEVEN','APERSONG','AGEZONG','AWAOREG','ABRAND','ABYSTAND'])\n",
    "third_party_insurance = np.array(['AWAPART','AWABEDR','AWALAND'])\n",
    "daily_vehicle = np.array(['APERSAUT','AMOTSCO','ABROM'])\n",
    "work_heavy_vehicle = np.array(['AVRAAUT','ATRACTOR','AWERKT','AAANHANG','ABESAUT'])\n",
    "property_insurance = np.array(['AINBOED'])\n",
    "leisure_vehicle = np.array(['APLEZIER','AFIETS','AZEILPL'])\n",
    "\n",
    "all_policies = np.concatenate([life_accidents_health, third_party_insurance, daily_vehicle, work_heavy_vehicle, property_insurance, leisure_vehicle])\n",
    "\n",
    "featureTester.add('total_policies', X[all_policies].sum(axis=1), toScale=True)\n",
    "featureTester.remove_list(all_policies)\n",
    "X = featureTester.flush_to_df()\n",
    "\n",
    "print('|----- Après le regroupement -----|')\n",
    "model = featureTester.get_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "317819c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MHHUUR</th>\n",
       "      <td>1607.413278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MHKOOP</th>\n",
       "      <td>1605.011609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MZFONDS</th>\n",
       "      <td>802.201002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MZPART</th>\n",
       "      <td>801.486528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOPLLAAG</th>\n",
       "      <td>31.976265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRELGE</th>\n",
       "      <td>22.988768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFWEKIND</th>\n",
       "      <td>21.727982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRELOV</th>\n",
       "      <td>18.949109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOPLMIDD</th>\n",
       "      <td>18.107363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFALLEEN</th>\n",
       "      <td>15.636070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAUT1</th>\n",
       "      <td>15.386895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAUT0</th>\n",
       "      <td>14.866369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOPLHOOG</th>\n",
       "      <td>13.752276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFGEKIND</th>\n",
       "      <td>12.813090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINKM30</th>\n",
       "      <td>12.559181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MGODPR</th>\n",
       "      <td>11.980496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MINK4575</th>\n",
       "      <td>10.325475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSKC</th>\n",
       "      <td>10.027376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VIF\n",
       "MHHUUR    1607.413278\n",
       "MHKOOP    1605.011609\n",
       "MZFONDS    802.201002\n",
       "MZPART     801.486528\n",
       "MOPLLAAG    31.976265\n",
       "MRELGE      22.988768\n",
       "MFWEKIND    21.727982\n",
       "MRELOV      18.949109\n",
       "MOPLMIDD    18.107363\n",
       "MFALLEEN    15.636070\n",
       "MAUT1       15.386895\n",
       "MAUT0       14.866369\n",
       "MOPLHOOG    13.752276\n",
       "MFGEKIND    12.813090\n",
       "MINKM30     12.559181\n",
       "MGODPR      11.980496\n",
       "MINK4575    10.325475\n",
       "MSKC        10.027376"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "cols = X_train.columns\n",
    "\n",
    "df_vif = FeatureTools.vif(X_train, cols)\n",
    "df_vif[df_vif['VIF'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2de4a",
   "metadata": {},
   "source": [
    "(Rented house) MHHUUR $\\iff$ MHKOOP (Home owner) \\\n",
    "(National Health Service) MZFONDS $\\iff$ MZPART (Private health insurance)\n",
    "\n",
    "MOPLLAAG - MOPLMIDD - MOPLHOOG (retire une, devient catégorie de référence)\n",
    "\n",
    "MRELGE - MRELOV - MRELSA (retire une, devient catégorie de référence) (MRELOV, car plus facile a interpreter apres, marier ou habite ensemble ou sinon catégorie de référence aka other relation)\n",
    "\n",
    "MFWEKIND - MFGEKIND - MFALLEEN (meme chose que ^) (MFGEKIND)\n",
    "\n",
    "MAUT0 - MAUT1 - MAUT2 (mm chose) (MAUT0)\n",
    "\n",
    "MINK* (mm chose) (MINKM30)\n",
    "\n",
    "MGOD* (mm chose) (MGODOV)\n",
    "\n",
    "MBER* (mm chose) (MBERARBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d954f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureTester.remove_list(['MHHUUR', 'MZFONDS', 'MOPLLAAG', 'MRELOV', 'MFGEKIND', 'MAUT0', 'MINKM30', 'MGODOV', 'MBERARBO'])\n",
    "X = featureTester.flush_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "498a5dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                |     VIF |\n",
      "|:---------------|--------:|\n",
      "| total_policies | 9.87819 |\n",
      "| MSKA           | 8.15507 |\n",
      "| MSKC           | 7.76223 |\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "cols = X_train.columns\n",
    "\n",
    "df_vif = FeatureTools.vif(X_train, cols)\n",
    "print(df_vif[df_vif['VIF'] >= 5].to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264caff4",
   "metadata": {},
   "source": [
    "Pour le reste des variables, je vais utiliser le score Z pour voir si elle sont significative ou pas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee1f42",
   "metadata": {},
   "source": [
    "$$H_0 : w_i = 0\\\\\n",
    "H_1 : w_i \\neq 0 \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bbbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "model = featureTester.get_trained_model(print_stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562929e",
   "metadata": {},
   "source": [
    "Elles contiennent tous $0$, il y a la possibilité que l'effet de ces variables soit nul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a93df93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Variable       |      $w_i$ |   $\\sigma$ |      $Z$ |     $b_i$ |     $b_s$ |\n",
       "|---:|:---------------|-----------:|-----------:|---------:|----------:|----------:|\n",
       "| 17 | MSKA           | -0.0337001 |  0.0982806 | 0.342896 | -0.22633  | 0.15893   |\n",
       "| 20 | MSKC           | -0.109832  |  0.0758362 | 1.44828  | -0.258471 | 0.0388066 |\n",
       "| 60 | total_policies |  0.102733  |  0.169785  | 0.605078 | -0.230046 | 0.435512  |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = FeatureTools.fisher_info(X_train.to_numpy(), model.w, model.b)\n",
    "cov_matrix = np.linalg.inv(fi)\n",
    "std = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "z_scores = model.w / std\n",
    "\n",
    "z_scores_df = pd.DataFrame({\n",
    "    'Variable': X_train.columns,\n",
    "    '$w_i$': model.w,\n",
    "    r'$\\sigma$': std,\n",
    "    '$Z$': abs(z_scores)\n",
    "})\n",
    "\n",
    "z_scores_df['$b_i$'] = z_scores_df['$w_i$'] - 1.96 * z_scores_df[r'$\\sigma$']\n",
    "z_scores_df['$b_s$'] = z_scores_df['$w_i$'] + 1.96 * z_scores_df[r'$\\sigma$']\n",
    "\n",
    "vars = ['total_policies', 'MSKA', 'MSKC']\n",
    "\n",
    "Markdown(z_scores_df[z_scores_df['Variable'].isin(vars)].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "203c4ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|      | Target         | Variable   |      coef |\n",
       "|-----:|:---------------|:-----------|----------:|\n",
       "| 3660 | total_policies | Intercept  | -1.21704  |\n",
       "| 3710 | total_policies | PFIETS     |  0.882518 |\n",
       "| 3700 | total_policies | PAANHANG   |  0.517393 |\n",
       "| 3693 | total_policies | PWAPART    |  0.410282 |\n",
       "| 3702 | total_policies | PWERKT     |  0.388062 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "cols = X_train.columns\n",
    "\n",
    "df_vif = FeatureTools.vif(X_train, cols, return_coef=True)\n",
    "Markdown(df_vif[df_vif['Target'] == 'total_policies'].sort_values(by='coef', key=abs, ascending=False).head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc9e5336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| VIF   |\n",
      "|-------|\n"
     ]
    }
   ],
   "source": [
    "vars = ['total_policies', 'MSKA', 'MSKC']\n",
    "featureTester.remove_list(vars)\n",
    "X = featureTester.flush_to_df()\n",
    "\n",
    "X_train, y_train, X_val, y_val = featureTester.return_split_train_eval()\n",
    "cols = X_train.columns\n",
    "\n",
    "df_vif = FeatureTools.vif(X_train, cols)\n",
    "print(df_vif[df_vif['VIF'] >= 5].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93ab5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = featureTester.get_trained_model(print_stats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0c4c5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | feature   |   $\\beta_n$ |   $OR$ |   $bi_{OR}$ |   $bs_{OR}$ |\n",
       "|---:|:----------|------------:|-------:|------------:|------------:|\n",
       "| 33 | PPERSAUT  |      0.1848 | 1.203  |      1.1456 |      1.2633 |\n",
       "| 45 | PBRAND    |      0.0925 | 1.0969 |      1.0076 |      1.194  |\n",
       "| 16 | MBERARBG  |     -0.1017 | 0.9033 |      0.8182 |      0.9973 |\n",
       "|  4 | MGODPR    |     -0.1219 | 0.8852 |      0.7894 |      0.9928 |\n",
       "|  8 | MFALLEEN  |     -0.1654 | 0.8476 |      0.7584 |      0.9472 |\n",
       "|  5 | MGODGE    |     -0.1766 | 0.8382 |      0.7456 |      0.9423 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(FeatureTools.or_with_ic(model, X_train.to_numpy(), X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eec5ce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC         : 0.7715\n",
      "Precision   : 0.1796\n",
      "Recall      : 0.5286\n",
      "F1          : 0.2681\n",
      "Threshold   : 0.1000\n",
      "[[926 169]\n",
      " [ 33  37]]\n"
     ]
    }
   ],
   "source": [
    "model = featureTester.get_trained_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
